#!/usr/bin/env python3
"""
ä¼˜åŒ–åçš„Agentæµ‹è¯• - éªŒè¯æŸ¥è¯¢åˆ†ç±»å™¨æ•ˆæœ
"""

import asyncio
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.agents.langgraph.standard_agent import get_standard_agent
from app.agents.langgraph.query_classifier import query_classifier

async def test_optimized_agent():
    """æµ‹è¯•ä¼˜åŒ–åçš„Agent"""
    print("ğŸš€ ä¼˜åŒ–åçš„Agentæµ‹è¯•")
    print("=" * 60)
    
    agent = get_standard_agent()
    
    # æµ‹è¯•ç”¨ä¾‹ - é‡ç‚¹æµ‹è¯•ä¹‹å‰å¤±è´¥çš„éšå«æ€§æŸ¥è¯¢
    test_cases = [
        {
            "category": "éšå«æ€§æŸ¥è¯¢æµ‹è¯•",
            "queries": [
                "æ¨èä¿¡æ€ä¹ˆå‡†å¤‡ï¼Ÿ",
                "æ–‡ä¹¦å†™ä½œæœ‰ä»€ä¹ˆæŠ€å·§ï¼Ÿ", 
                "é¢è¯•éœ€è¦æ³¨æ„ä»€ä¹ˆï¼Ÿ",
                "ç”³è¯·æ—¶é—´æ€ä¹ˆå®‰æ’ï¼Ÿ",
                "ç”³è¯·è´¹ç”¨å¤§æ¦‚å¤šå°‘ï¼Ÿ"
            ],
            "expected_kb_usage": True
        },
        {
            "category": "å…·ä½“åˆ†æ•°æŸ¥è¯¢",
            "queries": [
                "GPA 3.8èƒ½ç”³è¯·ä»€ä¹ˆå­¦æ ¡ï¼Ÿ",
                "æ‰˜ç¦105åˆ†å¤Ÿå—ï¼Ÿ",
                "GRE 325åˆ†ç”³è¯·CMUæœ‰å¸Œæœ›å—ï¼Ÿ"
            ],
            "expected_kb_usage": True
        },
        {
            "category": "ç½‘ç»œæœç´¢æŸ¥è¯¢",
            "queries": [
                "2024å¹´æœ€æ–°æ’å",
                "æœ€æ–°ç”³è¯·æ”¿ç­–å˜åŒ–",
                "ä»Šå¹´å½•å–ç‡æ€ä¹ˆæ ·ï¼Ÿ"
            ],
            "expected_kb_usage": False
        }
    ]
    
    total_tests = 0
    kb_usage_count = 0
    correct_tool_usage = 0
    
    for category_info in test_cases:
        category = category_info["category"]
        queries = category_info["queries"]
        expected_kb = category_info["expected_kb_usage"]
        
        print(f"\nğŸ“‹ {category}")
        print("-" * 40)
        
        for i, query in enumerate(queries, 1):
            total_tests += 1
            
            print(f"\nğŸ” æµ‹è¯• {total_tests}: {query}")
            
            # 1. é¦–å…ˆæ˜¾ç¤ºåˆ†ç±»å™¨åˆ†æ
            classification = query_classifier.classify_query(query)
            print(f"   ğŸ¤– åˆ†ç±»å™¨åˆ†æ:")
            print(f"      æ¨èå·¥å…·: {classification['recommended_tool']}")
            print(f"      ç½®ä¿¡åº¦: {classification['confidence']:.2f}")
            print(f"      åŸå› : {', '.join(classification['reasons'][:2])}")  # åªæ˜¾ç¤ºå‰ä¸¤ä¸ªåŸå› 
            
            try:
                # 2. æ‰§è¡ŒAgentæŸ¥è¯¢
                result = await agent.ainvoke({
                    "input": query,
                    "user_id": f"optimized_test_{total_tests}"
                })
                
                output = result.get('output', '')
                metadata = result.get('metadata', {})
                
                # 3. åˆ¤æ–­å®é™…å·¥å…·ä½¿ç”¨
                used_kb = ('çŸ¥è¯†åº“' in output or 
                          'æ¥æº' in output or 
                          'ğŸ“–' in output or
                          'CMU MSCS' in output or
                          'UC Berkeley EECS' in output or
                          'GPAï¼š3.8' in output or
                          'æ‰˜ç¦ï¼š105' in output)
                
                if used_kb:
                    kb_usage_count += 1
                    actual_status = "âœ… ä½¿ç”¨çŸ¥è¯†åº“"
                else:
                    actual_status = "âš ï¸ æœªä½¿ç”¨çŸ¥è¯†åº“"
                
                # 4. æ£€æŸ¥æ˜¯å¦ç¬¦åˆé¢„æœŸ
                if (used_kb and expected_kb) or (not used_kb and not expected_kb):
                    correct_tool_usage += 1
                    expectation_status = "âœ… ç¬¦åˆé¢„æœŸ"
                else:
                    expectation_status = "âŒ ä¸ç¬¦åˆé¢„æœŸ"
                
                print(f"   ğŸ“Š å®é™…ç»“æœ: {actual_status}")
                print(f"   ğŸ¯ é¢„æœŸè¯„ä¼°: {expectation_status}")
                print(f"   ğŸ“ å›ç­”é•¿åº¦: {len(output)}å­—ç¬¦")
                print(f"   â±ï¸  æ‰§è¡Œæ—¶é—´: {metadata.get('execution_time', 0):.2f}ç§’")
                
            except Exception as e:
                print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
            
            await asyncio.sleep(0.5)
    
    # ç”Ÿæˆä¼˜åŒ–æ•ˆæœæŠ¥å‘Š
    print(f"\nğŸ“Š ä¼˜åŒ–æ•ˆæœæ€»ç»“")
    print("=" * 40)
    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"çŸ¥è¯†åº“ä½¿ç”¨æ¬¡æ•°: {kb_usage_count}")
    print(f"çŸ¥è¯†åº“ä½¿ç”¨ç‡: {kb_usage_count/total_tests*100:.1f}%")
    print(f"æ­£ç¡®å·¥å…·é€‰æ‹©: {correct_tool_usage}")
    print(f"å·¥å…·é€‰æ‹©å‡†ç¡®ç‡: {correct_tool_usage/total_tests*100:.1f}%")
    
    # ä¼˜åŒ–æ•ˆæœè¯„ä¼°
    kb_usage_rate = kb_usage_count / total_tests
    tool_accuracy = correct_tool_usage / total_tests
    
    if kb_usage_rate >= 0.7 and tool_accuracy >= 0.8:
        grade = "ä¼˜ç§€"
        emoji = "ğŸ†"
        comment = "æŸ¥è¯¢åˆ†ç±»å™¨æ˜¾è‘—æå‡äº†çŸ¥è¯†åº“ä½¿ç”¨ç‡å’Œå·¥å…·é€‰æ‹©å‡†ç¡®æ€§"
    elif kb_usage_rate >= 0.5 and tool_accuracy >= 0.6:
        grade = "è‰¯å¥½"
        emoji = "ğŸ‘"
        comment = "ä¼˜åŒ–æ•ˆæœæ˜æ˜¾ï¼ŒçŸ¥è¯†åº“ä½¿ç”¨ç‡æœ‰è¾ƒå¤§æå‡"
    elif kb_usage_rate >= 0.3:
        grade = "ä¸€èˆ¬"
        emoji = "ğŸ¤”"
        comment = "æœ‰ä¸€å®šæ”¹è¿›ï¼Œä½†ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–"
    else:
        grade = "éœ€è¦æ”¹è¿›"
        emoji = "âš ï¸"
        comment = "ä¼˜åŒ–æ•ˆæœä¸æ˜æ˜¾ï¼Œéœ€è¦è°ƒæ•´ç­–ç•¥"
    
    print(f"\n{emoji} ä¼˜åŒ–æ•ˆæœè¯„ä»·: {grade}")
    print(f"   {comment}")
    
    # å…·ä½“æ”¹è¿›å»ºè®®
    if kb_usage_rate < 0.7:
        print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        print(f"   - æ‰©å±•å…³é”®è¯åº“ï¼Œå¢åŠ æ›´å¤šè§¦å‘è¯")
        print(f"   - æé«˜ç³»ç»Ÿæç¤ºçš„å¼ºåˆ¶æ€§")
        print(f"   - è€ƒè™‘æ·»åŠ æ›´ç²¾ç¡®çš„è¯­ä¹‰åˆ†æ")

if __name__ == "__main__":
    asyncio.run(test_optimized_agent())
