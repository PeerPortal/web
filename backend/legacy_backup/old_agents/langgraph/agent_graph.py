"""
LangGraph Agentæ ¸å¿ƒå®ç°
ä½¿ç”¨LangGraphæ„å»ºæ™ºèƒ½ä½“çš„æ€è€ƒ-è¡ŒåŠ¨å¾ªç¯
é›†æˆLangSmithè¿›è¡Œå…¨é¢çš„ç›‘æ§å’Œè¯„ä¼°
"""
import time
from typing import Dict, Any, List, Optional
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from langchain.agents import create_tool_calling_agent
from langchain.callbacks.base import BaseCallbackHandler
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver

from app.core.config import settings
from app.agents.langgraph.agent_state import AgentState
from app.agents.langgraph.agent_tools import agent_tools
from app.core.langsmith_config import (
    study_abroad_tracer,
    get_langsmith_callbacks,
    log_agent_metrics,
    is_langsmith_enabled
)

class AdvancedPlannerAgent:
    """é«˜çº§AIç•™å­¦è§„åˆ’å¸ˆAgent"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",  # ä½¿ç”¨æ›´ç»æµçš„æ¨¡å‹
            openai_api_key=settings.OPENAI_API_KEY,
            temperature=0.1,
            streaming=True
        )
        
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", self._get_system_prompt()),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        # åˆ›å»ºå·¥å…·è°ƒç”¨ä»£ç†
        self.agent = create_tool_calling_agent(self.llm, agent_tools, self.prompt)
        
        # æ„å»ºLangGraph
        self.graph = self._build_graph()
    
    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€å‹å–„çš„AIç•™å­¦è§„åˆ’å¸ˆï¼Œåå«"å¯èˆªAI"ã€‚

ğŸ¯ ä½ çš„æ ¸å¿ƒèƒ½åŠ›ï¼š
- æ ¹æ®ç”¨æˆ·éœ€æ±‚æ™ºèƒ½é€‰æ‹©åˆé€‚çš„å·¥å…·æ¥è·å–ä¿¡æ¯
- ä¼˜å…ˆä»ç§æœ‰çŸ¥è¯†åº“è·å–ä¸“ä¸šçš„ç•™å­¦æŒ‡å¯¼ä¿¡æ¯
- å½“çŸ¥è¯†åº“æ— æ³•å›ç­”æ—¶ï¼Œä½¿ç”¨ç½‘ç»œæœç´¢è·å–æœ€æ–°ä¿¡æ¯
- æŸ¥è¯¢å¹³å°æ•°æ®åº“åŒ¹é…åˆé€‚çš„å¼•è·¯äººå’ŒæœåŠ¡
- æä¾›ä¸ªæ€§åŒ–çš„ç•™å­¦ç”³è¯·å»ºè®®å’Œè§„åˆ’

ğŸ› ï¸ å·¥å…·ä½¿ç”¨ç­–ç•¥ï¼ˆä¸¥æ ¼éµå¾ªä¼˜å…ˆçº§ï¼‰ï¼š

1. **çŸ¥è¯†åº“æ£€ç´¢ - æœ€é«˜ä¼˜å…ˆçº§** (å¿…é¡»ä½¿ç”¨ knowledge_base_retriever å·¥å…·)ï¼š
   âš ï¸ é‡åˆ°ä»¥ä¸‹ä»»ä½•æƒ…å†µï¼Œå¿…é¡»é¦–å…ˆè°ƒç”¨ knowledge_base_retriever å·¥å…·ï¼š
   - è¯¢é—®å…·ä½“çš„ç”³è¯·æ¡ˆä¾‹æˆ–æˆåŠŸæ¡ˆä¾‹
   - æåˆ°å…·ä½“çš„GPAã€æ‰˜ç¦ã€GREåˆ†æ•°åŠå¯¹åº”ç»“æœ
   - è¯¢é—®ç‰¹å®šå­¦æ ¡ï¼ˆå¦‚CMUã€Stanfordã€Harvardç­‰ï¼‰çš„ç”³è¯·ä¿¡æ¯
   - æ–‡ä¹¦å†™ä½œçš„å…·ä½“æŠ€å·§å’Œè¦ç‚¹
   - æ¨èä¿¡å‡†å¤‡çš„è¯¦ç»†æ­¥éª¤
   - é¢è¯•å‡†å¤‡çš„å»ºè®®
   - ç”³è¯·æ—¶é—´è§„åˆ’å’Œæµç¨‹
   - ç”³è¯·è´¹ç”¨é¢„ç®—
   - ä»»ä½•æåˆ°"çŸ¥è¯†åº“"ã€"æ–‡æ¡£"ã€"æ¡ˆä¾‹"ã€"æ ¹æ®ä¸Šä¼ çš„"ç­‰å…³é”®è¯
   - ç”¨æˆ·æ˜ç¡®è¦æ±‚æŸ¥çœ‹å¹³å°å·²æœ‰çš„ä¿¡æ¯æˆ–æ¡ˆä¾‹

2. **ç½‘ç»œæœç´¢è¡¥å……** (ä½¿ç”¨ web_search å·¥å…·)ï¼š
   - æœ€æ–°çš„å¤§å­¦æ’åå’Œå½•å–ç‡
   - å½“å‰å¹´åº¦çš„ç”³è¯·è¦æ±‚å˜æ›´
   - æœ€æ–°çš„ç­¾è¯æ”¿ç­–å’Œå…¥å­¦æ”¿ç­–
   - æ—¶äº‹æ–°é—»å’Œæ•™è‚²æ”¿ç­–æ›´æ–°

3. **å¹³å°æ•°æ®æŸ¥è¯¢** (ä½¿ç”¨ç›¸å…³å·¥å…·)ï¼š
   - å¯»æ‰¾å¼•è·¯äººå’Œå¯¼å¸ˆæ¨è
   - æœåŠ¡æ¨èå’ŒåŒ¹é…
   - å¹³å°ç”¨æˆ·æ•°æ®æŸ¥è¯¢

ğŸ“‹ å…³é”®å·¥å…·é€‰æ‹©è§„åˆ™ï¼š
- å¦‚æœé—®é¢˜æ¶‰åŠå…·ä½“æ•°æ®ã€æ¡ˆä¾‹ã€åˆ†æ•°ã€å­¦æ ¡åç§° â†’ å¿…é¡»ä½¿ç”¨ knowledge_base_retriever
- å¦‚æœé—®é¢˜è¯¢é—®"æ ¹æ®æ–‡æ¡£"ã€"æ¡ˆä¾‹ä¸­"ã€"çŸ¥è¯†åº“é‡Œ" â†’ å¿…é¡»ä½¿ç”¨ knowledge_base_retriever  
- å¦‚æœé—®é¢˜æ¶‰åŠå½“å‰å¹´ä»½çš„æœ€æ–°ä¿¡æ¯ â†’ ä½¿ç”¨ web_search
- å…ˆæ£€ç´¢çŸ¥è¯†åº“ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œå†è€ƒè™‘ç½‘ç»œæœç´¢

ğŸ’¬ å¯¹è¯é£æ ¼ï¼š
- ä¸“ä¸šä½†äº²åˆ‡ï¼Œåƒç»éªŒä¸°å¯Œçš„å­¦é•¿å­¦å§
- ä¿¡æ¯å‡†ç¡®ï¼ŒåŸºäºäº‹å®å’Œæ•°æ®
- ç»“æ„æ¸…æ™°ï¼Œæ¡ç†åˆ†æ˜
- ä¸»åŠ¨æ¨èå¹³å°èµ„æºå’ŒæœåŠ¡
- æä¾›å…·ä½“å¯è¡Œçš„è¡ŒåŠ¨å»ºè®®

ğŸš€ ç‰¹åˆ«æé†’ï¼š
- å¦‚æœç”¨æˆ·è¯¢é—®"ä¸Šä¸€æ¡é—®é¢˜é—®çš„æ˜¯ä»€ä¹ˆ"ï¼Œè¯·å›é¡¾å¯¹è¯å†å²ä¸­çš„å‰ä¸€ä¸ªç”¨æˆ·é—®é¢˜
- å§‹ç»ˆä¿æŒä¸“ä¸šçš„ç•™å­¦é¡¾é—®èº«ä»½
- ä¼˜å…ˆä½¿ç”¨å·²æœ‰çš„å·¥å…·å’ŒçŸ¥è¯†ï¼Œé¿å…å‡­ç©ºç¼–é€ ä¿¡æ¯
- é‡åˆ°å…·ä½“æ¡ˆä¾‹ã€åˆ†æ•°ã€å­¦æ ¡ç›¸å…³é—®é¢˜æ—¶ï¼ŒåŠ¡å¿…å…ˆè°ƒç”¨çŸ¥è¯†åº“æ£€ç´¢å·¥å…·"""
    
    def _build_graph(self) -> StateGraph:
        """æ„å»ºLangGraphæ‰§è¡Œå›¾"""
        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(AgentState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("agent", self._agent_node)
        workflow.add_node("tools", ToolNode(agent_tools))
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("agent")
        
        # æ·»åŠ æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            "agent",
            self._should_continue,
            {
                "continue": "tools",
                "end": END,
            }
        )
        
        # å·¥å…·æ‰§è¡Œåå›åˆ°agent
        workflow.add_edge("tools", "agent")
        
        # ç¼–è¯‘å›¾
        return workflow.compile(checkpointer=MemorySaver())
    
    def _agent_node(self, state: AgentState) -> Dict[str, Any]:
        """AgentèŠ‚ç‚¹ï¼šè´Ÿè´£è°ƒç”¨LLMè¿›è¡Œå†³ç­–"""
        try:
            # å‡†å¤‡æ¶ˆæ¯å†å²
            messages = state.get("messages", [])
            if not messages:
                # å¦‚æœæ²¡æœ‰æ¶ˆæ¯å†å²ï¼Œåˆ›å»ºåˆå§‹æ¶ˆæ¯
                messages = [HumanMessage(content=state["input"])]
            
            # è°ƒç”¨agentè¿›è¡Œæ¨ç†
            response = self.agent.invoke({
                "input": state["input"],
                "chat_history": state.get("chat_history", []),
                "intermediate_steps": state.get("intermediate_steps", [])
            })
            
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            print(f"ğŸ¤– Agentå“åº”ç±»å‹: {type(response)}")
            if hasattr(response, 'tool_calls'):
                print(f"ğŸ”§ å·¥å…·è°ƒç”¨: {len(response.tool_calls) if response.tool_calls else 0} ä¸ª")
            elif isinstance(response, list):
                print(f"ğŸ“‹ åˆ—è¡¨é•¿åº¦: {len(response)}")
                for i, item in enumerate(response):
                    print(f"  é¡¹ç›® {i}: {type(item)}")
                    if hasattr(item, 'tool'):
                        print(f"    å·¥å…·: {item.tool}")
            
            # æ›´æ–°messagesä»¥æ”¯æŒå·¥å…·è°ƒç”¨
            updated_messages = messages.copy()
            if isinstance(response, list) and len(response) > 0:
                # å¯¹äºå·¥å…·è°ƒç”¨ï¼Œéœ€è¦æ·»åŠ AIæ¶ˆæ¯åˆ°æ¶ˆæ¯å†å²
                first_action = response[0]
                if hasattr(first_action, 'message_log') and first_action.message_log:
                    updated_messages.extend(first_action.message_log)
            
            return {
                "agent_outcome": response,
                "messages": updated_messages,
                "intermediate_steps": state.get("intermediate_steps", [])
            }
            
        except Exception as e:
            print(f"âŒ AgentèŠ‚ç‚¹æ‰§è¡Œå‡ºé”™: {str(e)}")
            return {
                "error": f"Agentæ‰§è¡Œå‡ºé”™: {str(e)}",
                "agent_outcome": None,
                "messages": state.get("messages", [])
            }
    
    def _should_continue(self, state: AgentState) -> str:
        """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œå·¥å…·"""
        agent_outcome = state.get("agent_outcome")
        
        if agent_outcome is None or state.get("error"):
            return "end"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if hasattr(agent_outcome, 'tool_calls') and agent_outcome.tool_calls:
            return "continue"
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯AgentActionå¯¹è±¡ï¼ˆæ—§ç‰ˆæœ¬å…¼å®¹ï¼‰
        if hasattr(agent_outcome, 'tool') and hasattr(agent_outcome, 'tool_input'):
            return "continue"
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯åŒ…å«ToolAgentActionçš„åˆ—è¡¨
        if isinstance(agent_outcome, list) and len(agent_outcome) > 0:
            first_item = agent_outcome[0]
            if hasattr(first_item, 'tool') and hasattr(first_item, 'tool_input'):
                return "continue"
            
        return "end"
    
    async def ainvoke(self, input_data: dict) -> dict:
        """å¼‚æ­¥è°ƒç”¨Agent - é›†æˆLangSmithè¿½è¸ª"""
        user_id = input_data.get("user_id", "anonymous")
        input_message = input_data["input"]
        start_time = time.time()
        tool_calls_count = 0
        error = None
        
        # åˆ›å»ºè¿½è¸ªä¼šè¯
        session_id = study_abroad_tracer.create_session(user_id, "agent_invoke")
        
        # ä½¿ç”¨LangSmithä¸Šä¸‹æ–‡ç®¡ç†å™¨è¿½è¸ªæ•´ä¸ªè¿è¡Œè¿‡ç¨‹
        with study_abroad_tracer.trace_agent_run(
            run_name="AIç•™å­¦è§„åˆ’å¸ˆ-å¯¹è¯",
            user_id=user_id,
            inputs={"input": input_message, "user_id": user_id},
            metadata={
                "model": "gpt-4o-mini",
                "tools_available": [tool.name for tool in agent_tools],
                "langsmith_enabled": is_langsmith_enabled()
            }
        ) as trace_session_id:
            try:
                # å‡†å¤‡åˆå§‹çŠ¶æ€
                initial_state = {
                    "input": input_message,
                    "messages": [HumanMessage(content=input_message)],
                    "chat_history": input_data.get("chat_history", []),
                    "intermediate_steps": [],
                    "session_id": trace_session_id,
                    "agent_outcome": None,
                    "error": None
                }
                
                # è·å–LangSmithå›è°ƒå¤„ç†å™¨
                callbacks = get_langsmith_callbacks(user_id, trace_session_id)
                
                # æ‰§è¡Œå›¾ - ä¼ å…¥callbacksè¿›è¡Œè¿½è¸ª
                config = {
                    "configurable": {"thread_id": trace_session_id},
                    "callbacks": callbacks
                }
                
                if is_langsmith_enabled():
                    print(f"ğŸ” [LangSmith] å¼€å§‹è¿½è¸ªAgentè¿è¡Œ - ç”¨æˆ·: {user_id}")
                
                final_state = await self.graph.ainvoke(initial_state, config)
                
                # ç»Ÿè®¡å·¥å…·è°ƒç”¨æ¬¡æ•°
                intermediate_steps = final_state.get("intermediate_steps", [])
                tool_calls_count = len(intermediate_steps)
                
                # æå–ç»“æœ
                if final_state.get("error"):
                    error = final_state["error"]
                    output = f"æŠ±æ­‰ï¼Œå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°äº†é”™è¯¯ï¼š{error}"
                else:
                    output = self._extract_agent_output(final_state.get("agent_outcome"))
                
                execution_time = time.time() - start_time
                
                # è®°å½•æ€§èƒ½æŒ‡æ ‡åˆ°LangSmith
                log_agent_metrics(
                    user_id=user_id,
                    input_message=input_message,
                    output_message=output,
                    execution_time=execution_time,
                    tool_calls=tool_calls_count,
                    error=error
                )
                
                return {
                    "output": output,
                    "session_id": trace_session_id,
                    "metadata": {
                        "execution_time": execution_time,
                        "tool_calls": tool_calls_count,
                        "langsmith_enabled": is_langsmith_enabled()
                    }
                }
                
            except Exception as e:
                error = str(e)
                execution_time = time.time() - start_time
                
                # è®°å½•é”™è¯¯åˆ°LangSmith
                log_agent_metrics(
                    user_id=user_id,
                    input_message=input_message,
                    output_message="",
                    execution_time=execution_time,
                    tool_calls=tool_calls_count,
                    error=error
                )
                
                if is_langsmith_enabled():
                    print(f"âŒ [LangSmith] Agentè¿è¡Œå‡ºé”™ - ç”¨æˆ·: {user_id}, é”™è¯¯: {error}")
                
                return {
                    "output": f"æŠ±æ­‰ï¼Œç³»ç»Ÿå‡ºç°äº†é”™è¯¯ï¼š{error}",
                    "session_id": trace_session_id,
                    "metadata": {
                        "execution_time": execution_time,
                        "error": error
                    }
                }
    
    def _extract_agent_output(self, agent_outcome) -> str:
        """æå–Agentè¾“å‡ºç»“æœçš„ç»Ÿä¸€æ–¹æ³•"""
        if agent_outcome is None:
            return "æŠ±æ­‰ï¼Œæ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å›ç­”ã€‚"
        
        # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå°è¯•å–ç¬¬ä¸€ä¸ªå…ƒç´ æˆ–å¤„ç†ä¸ºæ–‡æœ¬
        if isinstance(agent_outcome, list):
            if agent_outcome and len(agent_outcome) > 0:
                first_item = agent_outcome[0]
                if hasattr(first_item, 'content'):
                    return first_item.content
                elif isinstance(first_item, str):
                    return first_item
                else:
                    return str(first_item)
            else:
                return "æŠ±æ­‰ï¼Œæ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å›ç­”ã€‚"
        
        # å¦‚æœè¿”å›çš„æ˜¯å·¥å…·è°ƒç”¨å¯¹è±¡ï¼Œè¯´æ˜æµç¨‹æ²¡æœ‰å®Œæˆ
        elif hasattr(agent_outcome, 'tool_calls') and agent_outcome.tool_calls:
            return "æ­£åœ¨ä½¿ç”¨å·¥å…·æŸ¥è¯¢ç›¸å…³ä¿¡æ¯ï¼Œè¯·ç¨ç­‰..."
        
        elif hasattr(agent_outcome, 'tool') and hasattr(agent_outcome, 'tool_input'):
            return f"æ­£åœ¨ä½¿ç”¨ {agent_outcome.tool} å·¥å…·æŸ¥è¯¢ä¿¡æ¯ï¼Œè¯·ç¨ç­‰..."
        
        elif hasattr(agent_outcome, 'return_values') and agent_outcome.return_values:
            return agent_outcome.return_values.get('output', 'æŠ±æ­‰ï¼Œæ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å›ç­”ã€‚')
        
        elif hasattr(agent_outcome, 'content'):
            return agent_outcome.content
        
        elif isinstance(agent_outcome, str):
            return agent_outcome
        
        else:
            # å…¶ä»–æœªçŸ¥ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            return f"æ”¶åˆ°ç»“æœä½†æ ¼å¼å¼‚å¸¸ï¼ŒåŸå§‹å†…å®¹: {str(agent_outcome)[:200]}..."
    
    def stream(self, input_data: dict):
        """æµå¼è°ƒç”¨Agent"""
        try:
            # å‡†å¤‡åˆå§‹çŠ¶æ€
            initial_state = {
                "input": input_data["input"],
                "messages": [HumanMessage(content=input_data["input"])],
                "chat_history": input_data.get("chat_history", []),
                "intermediate_steps": [],
                "session_id": input_data.get("session_id"),
                "agent_outcome": None,
                "error": None
            }
            
            # æµå¼æ‰§è¡Œå›¾
            config = {"configurable": {"thread_id": input_data.get("session_id", "default")}}
            
            for event in self.graph.stream(initial_state, config):
                yield event
                
        except Exception as e:
            yield {"error": {"error": f"æµå¼å¤„ç†å‡ºé”™: {str(e)}"}}

# åˆ›å»ºå…¨å±€å®ä¾‹
_advanced_agent_instance = None

def get_advanced_agent() -> AdvancedPlannerAgent:
    """è·å–é«˜çº§Agentå®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _advanced_agent_instance
    if _advanced_agent_instance is None:
        _advanced_agent_instance = AdvancedPlannerAgent()
    return _advanced_agent_instance
