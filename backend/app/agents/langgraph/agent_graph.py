"""
LangGraph Agentæ ¸å¿ƒå®ç°
ä½¿ç”¨LangGraphæ„å»ºæ™ºèƒ½ä½“çš„æ€è€ƒ-è¡ŒåŠ¨å¾ªç¯
é›†æˆLangSmithè¿›è¡Œå…¨é¢çš„ç›‘æ§å’Œè¯„ä¼°
"""
import time
from typing import Dict, Any, List, Optional
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from langchain.agents import create_tool_calling_agent
from langchain.callbacks.base import BaseCallbackHandler
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver

from app.core.config import settings
from app.agents.langgraph.agent_state import AgentState
from app.agents.langgraph.agent_tools import agent_tools
from app.core.langsmith_config import (
    study_abroad_tracer,
    get_langsmith_callbacks,
    log_agent_metrics,
    is_langsmith_enabled
)

class AdvancedPlannerAgent:
    """é«˜çº§AIç•™å­¦è§„åˆ’å¸ˆAgent"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",  # ä½¿ç”¨æ›´ç»æµçš„æ¨¡å‹
            openai_api_key=settings.OPENAI_API_KEY,
            temperature=0.1,
            streaming=True
        )
        
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", self._get_system_prompt()),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        # åˆ›å»ºå·¥å…·è°ƒç”¨ä»£ç†
        self.agent = create_tool_calling_agent(self.llm, agent_tools, self.prompt)
        
        # æ„å»ºLangGraph
        self.graph = self._build_graph()
    
    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€å‹å–„çš„AIç•™å­¦è§„åˆ’å¸ˆï¼Œåå«"å¯èˆªAI"ã€‚

ğŸ¯ ä½ çš„æ ¸å¿ƒèƒ½åŠ›ï¼š
- æ ¹æ®ç”¨æˆ·éœ€æ±‚æ™ºèƒ½é€‰æ‹©åˆé€‚çš„å·¥å…·æ¥è·å–ä¿¡æ¯
- ä¼˜å…ˆä»ç§æœ‰çŸ¥è¯†åº“è·å–ä¸“ä¸šçš„ç•™å­¦æŒ‡å¯¼ä¿¡æ¯
- å½“çŸ¥è¯†åº“æ— æ³•å›ç­”æ—¶ï¼Œä½¿ç”¨ç½‘ç»œæœç´¢è·å–æœ€æ–°ä¿¡æ¯
- æŸ¥è¯¢å¹³å°æ•°æ®åº“åŒ¹é…åˆé€‚çš„å¼•è·¯äººå’ŒæœåŠ¡
- æä¾›ä¸ªæ€§åŒ–çš„ç•™å­¦ç”³è¯·å»ºè®®å’Œè§„åˆ’

ğŸ› ï¸ å·¥å…·ä½¿ç”¨ç­–ç•¥ï¼š
1. **çŸ¥è¯†åº“ä¼˜å…ˆ**: å¯¹äºç•™å­¦ç”³è¯·ç­–ç•¥ã€æ–‡ä¹¦å†™ä½œã€æˆåŠŸæ¡ˆä¾‹ç­‰é—®é¢˜ï¼Œä¼˜å…ˆä½¿ç”¨çŸ¥è¯†åº“æ£€ç´¢
2. **ç½‘ç»œæœç´¢è¡¥å……**: å¯¹äºæœ€æ–°æ’åã€ç”³è¯·è¦æ±‚å˜æ›´ã€æ—¶äº‹æ–°é—»ç­‰ï¼Œä½¿ç”¨ç½‘ç»œæœç´¢
3. **å¹³å°æ•°æ®æŸ¥è¯¢**: å¯¹äºå¯»æ‰¾å¼•è·¯äººã€æœåŠ¡æ¨èç­‰ï¼Œä½¿ç”¨å¹³å°æ•°æ®åº“å·¥å…·
4. **è®°å¿†è¿è´¯æ€§**: ç»“åˆå¯¹è¯å†å²æä¾›è¿è´¯çš„ä¸ªæ€§åŒ–å»ºè®®

ğŸ’¬ å¯¹è¯é£æ ¼ï¼š
- ä¸“ä¸šä½†äº²åˆ‡ï¼Œåƒç»éªŒä¸°å¯Œçš„å­¦é•¿å­¦å§
- ä¿¡æ¯å‡†ç¡®ï¼ŒåŸºäºäº‹å®å’Œæ•°æ®
- ç»“æ„æ¸…æ™°ï¼Œæ¡ç†åˆ†æ˜
- ä¸»åŠ¨æ¨èå¹³å°èµ„æºå’ŒæœåŠ¡
- æä¾›å…·ä½“å¯è¡Œçš„è¡ŒåŠ¨å»ºè®®

ğŸš€ ç‰¹åˆ«æé†’ï¼š
- å¦‚æœç”¨æˆ·è¯¢é—®"ä¸Šä¸€æ¡é—®é¢˜é—®çš„æ˜¯ä»€ä¹ˆ"ï¼Œè¯·å›é¡¾å¯¹è¯å†å²ä¸­çš„å‰ä¸€ä¸ªç”¨æˆ·é—®é¢˜
- å§‹ç»ˆä¿æŒä¸“ä¸šçš„ç•™å­¦é¡¾é—®èº«ä»½
- ä¼˜å…ˆä½¿ç”¨å·²æœ‰çš„å·¥å…·å’ŒçŸ¥è¯†ï¼Œé¿å…å‡­ç©ºç¼–é€ ä¿¡æ¯"""
    
    def _build_graph(self) -> StateGraph:
        """æ„å»ºLangGraphæ‰§è¡Œå›¾"""
        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(AgentState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("agent", self._agent_node)
        workflow.add_node("tools", ToolNode(agent_tools))
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("agent")
        
        # æ·»åŠ æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            "agent",
            self._should_continue,
            {
                "continue": "tools",
                "end": END,
            }
        )
        
        # å·¥å…·æ‰§è¡Œåå›åˆ°agent
        workflow.add_edge("tools", "agent")
        
        # ç¼–è¯‘å›¾
        return workflow.compile(checkpointer=MemorySaver())
    
    def _agent_node(self, state: AgentState) -> Dict[str, Any]:
        """AgentèŠ‚ç‚¹ï¼šè´Ÿè´£è°ƒç”¨LLMè¿›è¡Œå†³ç­–"""
        try:
            # è°ƒç”¨agentè¿›è¡Œæ¨ç†
            response = self.agent.invoke({
                "input": state["input"],
                "chat_history": state.get("chat_history", []),
                "intermediate_steps": state.get("intermediate_steps", [])
            })
            
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            print(f"ğŸ¤– Agentå“åº”ç±»å‹: {type(response)}")
            if hasattr(response, 'tool_calls'):
                print(f"ğŸ”§ å·¥å…·è°ƒç”¨: {len(response.tool_calls) if response.tool_calls else 0} ä¸ª")
            elif isinstance(response, list):
                print(f"ğŸ“‹ åˆ—è¡¨é•¿åº¦: {len(response)}")
                for i, item in enumerate(response):
                    print(f"  é¡¹ç›® {i}: {type(item)}")
            
            return {
                "agent_outcome": response,
                "intermediate_steps": state.get("intermediate_steps", [])
            }
            
        except Exception as e:
            print(f"âŒ AgentèŠ‚ç‚¹æ‰§è¡Œå‡ºé”™: {str(e)}")
            return {
                "error": f"Agentæ‰§è¡Œå‡ºé”™: {str(e)}",
                "agent_outcome": None
            }
    
    def _should_continue(self, state: AgentState) -> str:
        """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œå·¥å…·"""
        agent_outcome = state.get("agent_outcome")
        
        if agent_outcome is None or state.get("error"):
            return "end"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if hasattr(agent_outcome, 'tool_calls') and agent_outcome.tool_calls:
            return "continue"
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯AgentActionå¯¹è±¡ï¼ˆæ—§ç‰ˆæœ¬å…¼å®¹ï¼‰
        if hasattr(agent_outcome, 'tool') and hasattr(agent_outcome, 'tool_input'):
            return "continue"
            
        return "end"
    
    async def ainvoke(self, input_data: dict) -> dict:
        """å¼‚æ­¥è°ƒç”¨Agent - é›†æˆLangSmithè¿½è¸ª"""
        user_id = input_data.get("user_id", "anonymous")
        input_message = input_data["input"]
        start_time = time.time()
        tool_calls_count = 0
        error = None
        
        # åˆ›å»ºè¿½è¸ªä¼šè¯
        session_id = study_abroad_tracer.create_session(user_id, "agent_invoke")
        
        # ä½¿ç”¨LangSmithä¸Šä¸‹æ–‡ç®¡ç†å™¨è¿½è¸ªæ•´ä¸ªè¿è¡Œè¿‡ç¨‹
        with study_abroad_tracer.trace_agent_run(
            run_name="AIç•™å­¦è§„åˆ’å¸ˆ-å¯¹è¯",
            user_id=user_id,
            inputs={"input": input_message, "user_id": user_id},
            metadata={
                "model": "gpt-4o-mini",
                "tools_available": [tool.name for tool in agent_tools],
                "langsmith_enabled": is_langsmith_enabled()
            }
        ) as trace_session_id:
            try:
                # å‡†å¤‡åˆå§‹çŠ¶æ€
                initial_state = {
                    "input": input_message,
                    "chat_history": input_data.get("chat_history", []),
                    "intermediate_steps": [],
                    "session_id": trace_session_id,
                    "agent_outcome": None,
                    "error": None
                }
                
                # è·å–LangSmithå›è°ƒå¤„ç†å™¨
                callbacks = get_langsmith_callbacks(user_id, trace_session_id)
                
                # æ‰§è¡Œå›¾ - ä¼ å…¥callbacksè¿›è¡Œè¿½è¸ª
                config = {
                    "configurable": {"thread_id": trace_session_id},
                    "callbacks": callbacks
                }
                
                if is_langsmith_enabled():
                    print(f"ğŸ” [LangSmith] å¼€å§‹è¿½è¸ªAgentè¿è¡Œ - ç”¨æˆ·: {user_id}")
                
                final_state = await self.graph.ainvoke(initial_state, config)
                
                # ç»Ÿè®¡å·¥å…·è°ƒç”¨æ¬¡æ•°
                intermediate_steps = final_state.get("intermediate_steps", [])
                tool_calls_count = len(intermediate_steps)
                
                # æå–ç»“æœ
                if final_state.get("error"):
                    error = final_state["error"]
                    output = f"æŠ±æ­‰ï¼Œå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°äº†é”™è¯¯ï¼š{error}"
                else:
                    output = self._extract_agent_output(final_state.get("agent_outcome"))
                
                execution_time = time.time() - start_time
                
                # è®°å½•æ€§èƒ½æŒ‡æ ‡åˆ°LangSmith
                log_agent_metrics(
                    user_id=user_id,
                    input_message=input_message,
                    output_message=output,
                    execution_time=execution_time,
                    tool_calls=tool_calls_count,
                    error=error
                )
                
                return {
                    "output": output,
                    "session_id": trace_session_id,
                    "metadata": {
                        "execution_time": execution_time,
                        "tool_calls": tool_calls_count,
                        "langsmith_enabled": is_langsmith_enabled()
                    }
                }
                
            except Exception as e:
                error = str(e)
                execution_time = time.time() - start_time
                
                # è®°å½•é”™è¯¯åˆ°LangSmith
                log_agent_metrics(
                    user_id=user_id,
                    input_message=input_message,
                    output_message="",
                    execution_time=execution_time,
                    tool_calls=tool_calls_count,
                    error=error
                )
                
                if is_langsmith_enabled():
                    print(f"âŒ [LangSmith] Agentè¿è¡Œå‡ºé”™ - ç”¨æˆ·: {user_id}, é”™è¯¯: {error}")
                
                return {
                    "output": f"æŠ±æ­‰ï¼Œç³»ç»Ÿå‡ºç°äº†é”™è¯¯ï¼š{error}",
                    "session_id": trace_session_id,
                    "metadata": {
                        "execution_time": execution_time,
                        "error": error
                    }
                }
    
    def _extract_agent_output(self, agent_outcome) -> str:
        """æå–Agentè¾“å‡ºç»“æœçš„ç»Ÿä¸€æ–¹æ³•"""
        if agent_outcome is None:
            return "æŠ±æ­‰ï¼Œæ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å›ç­”ã€‚"
        
        # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå°è¯•å–ç¬¬ä¸€ä¸ªå…ƒç´ æˆ–å¤„ç†ä¸ºæ–‡æœ¬
        if isinstance(agent_outcome, list):
            if agent_outcome and len(agent_outcome) > 0:
                first_item = agent_outcome[0]
                if hasattr(first_item, 'content'):
                    return first_item.content
                elif isinstance(first_item, str):
                    return first_item
                else:
                    return str(first_item)
            else:
                return "æŠ±æ­‰ï¼Œæ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å›ç­”ã€‚"
        
        # å¦‚æœè¿”å›çš„æ˜¯å·¥å…·è°ƒç”¨å¯¹è±¡ï¼Œè¯´æ˜æµç¨‹æ²¡æœ‰å®Œæˆ
        elif hasattr(agent_outcome, 'tool_calls') and agent_outcome.tool_calls:
            return "æ­£åœ¨ä½¿ç”¨å·¥å…·æŸ¥è¯¢ç›¸å…³ä¿¡æ¯ï¼Œè¯·ç¨ç­‰..."
        
        elif hasattr(agent_outcome, 'tool') and hasattr(agent_outcome, 'tool_input'):
            return f"æ­£åœ¨ä½¿ç”¨ {agent_outcome.tool} å·¥å…·æŸ¥è¯¢ä¿¡æ¯ï¼Œè¯·ç¨ç­‰..."
        
        elif hasattr(agent_outcome, 'return_values') and agent_outcome.return_values:
            return agent_outcome.return_values.get('output', 'æŠ±æ­‰ï¼Œæ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å›ç­”ã€‚')
        
        elif hasattr(agent_outcome, 'content'):
            return agent_outcome.content
        
        elif isinstance(agent_outcome, str):
            return agent_outcome
        
        else:
            # å…¶ä»–æœªçŸ¥ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            return f"æ”¶åˆ°ç»“æœä½†æ ¼å¼å¼‚å¸¸ï¼ŒåŸå§‹å†…å®¹: {str(agent_outcome)[:200]}..."
    
    def stream(self, input_data: dict):
        """æµå¼è°ƒç”¨Agent"""
        try:
            # å‡†å¤‡åˆå§‹çŠ¶æ€
            initial_state = {
                "input": input_data["input"],
                "chat_history": input_data.get("chat_history", []),
                "intermediate_steps": [],
                "session_id": input_data.get("session_id"),
                "agent_outcome": None,
                "error": None
            }
            
            # æµå¼æ‰§è¡Œå›¾
            config = {"configurable": {"thread_id": input_data.get("session_id", "default")}}
            
            for event in self.graph.stream(initial_state, config):
                yield event
                
        except Exception as e:
            yield {"error": {"error": f"æµå¼å¤„ç†å‡ºé”™: {str(e)}"}}

# åˆ›å»ºå…¨å±€å®ä¾‹
_advanced_agent_instance = None

def get_advanced_agent() -> AdvancedPlannerAgent:
    """è·å–é«˜çº§Agentå®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _advanced_agent_instance
    if _advanced_agent_instance is None:
        _advanced_agent_instance = AdvancedPlannerAgent()
    return _advanced_agent_instance
